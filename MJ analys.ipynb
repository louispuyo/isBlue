{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Strains MJ analyse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e8ce9c49b14934969844eb7ea47d4f"
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Strain</th>\n",
       "      <th>Type</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Effects</th>\n",
       "      <th>Flavor</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>976</td>\n",
       "      <td>Guptilla</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Happy,Relaxed,Euphoric,Focused,Sleepy</td>\n",
       "      <td>Grape,Pepper,Orange</td>\n",
       "      <td>Guptilla is a potent indica-dominant cross bre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1744</td>\n",
       "      <td>Rafael</td>\n",
       "      <td>sativa</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Uplifted,Happy,Energentic\\n</td>\n",
       "      <td>Pine</td>\n",
       "      <td>Rafael (or Raphael) is a sativa-dominant strai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>Bcn-Diesel</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Sleepy,Focused,Happy,Hungry</td>\n",
       "      <td>None</td>\n",
       "      <td>BCN Diesel by Kannabia Seed Company is a punge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>818</td>\n",
       "      <td>Frosty-Jesus</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Tingly,Creative,Euphoric,Focused,Happy</td>\n",
       "      <td>Diesel,Spicy/Herbal,Earthy</td>\n",
       "      <td>Frosty Jesus is a clone-only strain from Rebel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>Bad-Azz-Kush</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Bad Azz Kush by Barney’s Farm was created with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1577</td>\n",
       "      <td>Peyton-Manning</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Uplifted,Creative,Euphoric,Focused,Giggly</td>\n",
       "      <td>Earthy\\n</td>\n",
       "      <td>Peyton Manning is a horticultural homage to De...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1589</td>\n",
       "      <td>Pineapple-Calyx</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>2.5</td>\n",
       "      <td>None</td>\n",
       "      <td>Citrus,Earthy\\n</td>\n",
       "      <td>Pineapple Calyx from Calyx Garden is a hybrid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>Afrikaner</td>\n",
       "      <td>sativa</td>\n",
       "      <td>2.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Afrikaner by Cannabaal and master grower Waldo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>524</td>\n",
       "      <td>Chocoholic</td>\n",
       "      <td>hybrid</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Aroused,Sleepy,Tingly,Uplifted,Euphoric\\n</td>\n",
       "      <td>Vanilla\\n</td>\n",
       "      <td>Chocoholic by Mighty Irish Seeds is a flavorfu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1781</td>\n",
       "      <td>Rigger-Kush</td>\n",
       "      <td>indica</td>\n",
       "      <td>2.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Rigger Kush is a Hindu Kush phenotype out of A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2351 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Strain    Type  Rating  \\\n",
       "976          Guptilla  hybrid     5.0   \n",
       "1744           Rafael  sativa     5.0   \n",
       "157        Bcn-Diesel  hybrid     5.0   \n",
       "818      Frosty-Jesus  hybrid     5.0   \n",
       "160      Bad-Azz-Kush  hybrid     5.0   \n",
       "...               ...     ...     ...   \n",
       "1577   Peyton-Manning  hybrid     2.5   \n",
       "1589  Pineapple-Calyx  hybrid     2.5   \n",
       "54          Afrikaner  sativa     2.5   \n",
       "524        Chocoholic  hybrid     2.5   \n",
       "1781      Rigger-Kush  indica     2.5   \n",
       "\n",
       "                                        Effects                      Flavor  \\\n",
       "976       Happy,Relaxed,Euphoric,Focused,Sleepy         Grape,Pepper,Orange   \n",
       "1744                Uplifted,Happy,Energentic\\n                        Pine   \n",
       "157                 Sleepy,Focused,Happy,Hungry                        None   \n",
       "818      Tingly,Creative,Euphoric,Focused,Happy  Diesel,Spicy/Herbal,Earthy   \n",
       "160                                        None                        None   \n",
       "...                                         ...                         ...   \n",
       "1577  Uplifted,Creative,Euphoric,Focused,Giggly                    Earthy\\n   \n",
       "1589                                       None             Citrus,Earthy\\n   \n",
       "54                                         None                        None   \n",
       "524   Aroused,Sleepy,Tingly,Uplifted,Euphoric\\n                   Vanilla\\n   \n",
       "1781                                       None                        None   \n",
       "\n",
       "                                            Description  \n",
       "976   Guptilla is a potent indica-dominant cross bre...  \n",
       "1744  Rafael (or Raphael) is a sativa-dominant strai...  \n",
       "157   BCN Diesel by Kannabia Seed Company is a punge...  \n",
       "818   Frosty Jesus is a clone-only strain from Rebel...  \n",
       "160   Bad Azz Kush by Barney’s Farm was created with...  \n",
       "...                                                 ...  \n",
       "1577  Peyton Manning is a horticultural homage to De...  \n",
       "1589  Pineapple Calyx from Calyx Garden is a hybrid ...  \n",
       "54    Afrikaner by Cannabaal and master grower Waldo...  \n",
       "524   Chocoholic by Mighty Irish Seeds is a flavorfu...  \n",
       "1781  Rigger Kush is a Hindu Kush phenotype out of A...  \n",
       "\n",
       "[2351 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "ca = pd.read_csv('/home/snowden/airflow3/medecine/Cannabis_Strains_Features.csv')\n",
    "df = pd.DataFrame(ca)\n",
    "df\n",
    "Effect = df['Effects']\n",
    "Effect = Effect.str.replace('\\n', '').str.replace(' ', '').str.replace('Energentic', 'Energetic').str.replace('Dry','Drymouth').str.replace('Mouth', 'Drymouth')\n",
    "Effect = Effect.str.split(',', expand=True)\n",
    "eff_1 = Effect[0].unique()\n",
    "eff_2 = Effect[1].unique()\n",
    "eff_3 = Effect[2].unique()\n",
    "eff_4 = Effect[3].unique()\n",
    "\n",
    "\n",
    "\n",
    "container_effect = []\n",
    "for i in range(3):\n",
    "    for k in Effect[i].unique():\n",
    "        if k not in container_effect:\n",
    "            container_effect.append(k)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "df\n",
    "# bamboolib live code export\n",
    "df['Rating'] = df['Rating'].replace(np.nan, 2.5)\n",
    "df = df.sort_values(by=['Rating'], ascending=[None])\n",
    "df['Rating'] = df['Rating'].replace(0, 2.5)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Type = df['Type'].replace(['hybrid', 'sativa', 'indica'], [2,1,0])\n",
    "Effect.replace('None', 'null')\n",
    "container_effect = pd.Series(container_effect).replace(['Creative',\n",
    " 'Relaxed',\n",
    " 'Uplifted',\n",
    " 'Tingly',\n",
    " 'Happy',\n",
    " 'Energetic',\n",
    " 'Euphoric',\n",
    " 'Hungry',\n",
    " 'Talkative',\n",
    " 'Focused',\n",
    " 'Sleepy',\n",
    " 'null',\n",
    " 'Aroused',\n",
    " 'Giggly',\n",
    " 'Drymouth'], [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac7f2faa0f545d39ee4f29130046fb8"
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>Total</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2346</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2347</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2348</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2349</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2351 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1    2    3     4  Total  Target\n",
       "0     1.0   6.0  4.0  7.0   2.0   20.0     4.0\n",
       "1     2.0  13.0  1.0  5.0   6.0   27.0     4.7\n",
       "2     3.0   5.0  2.0  6.0   1.0   17.0     4.4\n",
       "3     4.0   1.0  8.0  2.0   3.0   18.0     4.2\n",
       "4     5.0   2.0  7.0  3.0   9.0   26.0     4.6\n",
       "...   ...   ...  ...  ...   ...    ...     ...\n",
       "2346  5.0   3.0  2.0  7.0   6.0   23.0     4.7\n",
       "2347  2.0   5.0  7.0  3.0  11.0   28.0     4.6\n",
       "2348  2.0  11.0  9.0  7.0   5.0   34.0     5.0\n",
       "2349  2.0  11.0  7.0  5.0   8.0   33.0     4.4\n",
       "2350  8.0   2.0  3.0  5.0  11.0   29.0     4.6\n",
       "\n",
       "[2351 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA = pd.DataFrame(Effect).replace(['Creative',\n",
    " 'Relaxed',\n",
    " 'Uplifted',\n",
    " 'Tingly',\n",
    " 'Happy',\n",
    " 'Energetic',\n",
    " 'Euphoric',\n",
    " 'Hungry',\n",
    " 'Talkative',\n",
    " 'Focused',\n",
    " 'Sleepy',\n",
    " 'null',\n",
    " 'Aroused',\n",
    " 'Giggly',\n",
    " 'Drymouth'], [1,2,3,4,5,6,7,8,9,10,11,0,13,14,15])\n",
    "\n",
    "DATA\n",
    "# bamboolib live code export\n",
    "DATA.columns = [str(column) for column in DATA.columns if column != (None or 'None')]\n",
    "DATA\n",
    "# bamboolib live code export\n",
    "DATAc = DATA.replace('None', 0)\n",
    "DATAc\n",
    "# bamboolib live code export\n",
    "DATAc.loc[DATAc['0'].isna(), '0'] = 0\n",
    "DATAc['0'] = DATAc['0'].astype(float)\n",
    "Data = DATAc\n",
    "Rate = df['Rating']\n",
    "Data\n",
    "# bamboolib live code export\n",
    "Data[\"Total\"] = Data['0']+Data['1']+Data['2']+Data['3']+Data['4']\n",
    "Data[\"Target\"] = Rate[:len(Data)]\n",
    "Data\n",
    "# bamboolib live code export\n",
    "Data['Target'] \n",
    "Data\n",
    "# bamboolib live code export\n",
    "\n",
    "# bamboolib live code export\n",
    "DATAc.loc[DATAc['0'].isna(), '0'] = 7.5\n",
    "DATAc.loc[DATAc['1'].isna(), '1'] = 7.5\n",
    "DATAc['2'] = DATAc['2'].replace(np.nan, 7.5)\n",
    "DATAc['3'] = DATAc['3'].replace(np.nan, 7.5)\n",
    "DATAc['4'] = DATAc['4'].replace(np.nan, 7.6)\n",
    "DATAc\n",
    "# bamboolib live code export\n",
    "DATAc['Total'] = DATAc['Total'].replace(np.nan, 35.1)\n",
    "DATAc['Target'] = DATAc['Target'].replace(np.nan, 2.5)\n",
    "DATAc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2351, 1)"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(DATAc['Target']).reshape(-1,1)\n",
    "x = np.array(DATAc['Total']).reshape(-1,1)\n",
    "\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### here we have clean the data that contains error and duplicated, perhapse we need unique value for our parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "model = KNeighborsClassifier()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
    "lab_enc = LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y_train)\n",
    "result_scores_encoded = lab_enc.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, training_scores_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11054421768707483"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test, result_scores_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bilan 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1537152580828134"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_train, training_scores_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11%  with sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### but now let's just move on a neural Network from scrach, take a lil'break before it !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the following program do not contains any Library 'all made program', exept numpy and pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from numpy import argmax\n",
    "# for array and dot product\n",
    "\n",
    "\n",
    "\n",
    "def data_wrapper(data, line, row, mode):\n",
    "    '''preprocessing -> transforme a list [1:15] into a one_to_hot:\n",
    "    ex: [1,0,0,0,1,0,1,0,1,1...]\n",
    "    this process will permit us to select the good feelings in the list \n",
    "    and allow the machine to make the difference between good or bad feelings\n",
    "    '''\n",
    "    data = data.str.casefold()\n",
    "    data = data.str.split(',')\n",
    "    data = data[line][row]\n",
    "    # define universe of possible input values\n",
    "    alphabet = 'abcdefghijklmnopqrstuvwxyz '\n",
    "\n",
    "    # define a mapping of chars to integers\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "    # integer encode input data\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "    #print(integer_encoded)\n",
    "    # one hot encode\n",
    "    onehot_encoded = list()\n",
    "    for value in integer_encoded:\n",
    "        letter = [0 for _ in range(len(alphabet))]\n",
    "        letter[value] = 1\n",
    "        onehot_encoded.append(letter)\n",
    "    #print(onehot_encoded)\n",
    "    # invert encoding\n",
    "    inverted = int_to_char[argmax(onehot_encoded[0])]\n",
    "    #print(inverted)\n",
    "    if mode == 'bin':\n",
    "        return onehot_encoded\n",
    "    else:\n",
    "        return integer_encoded\n",
    "\n",
    "class Neural_Network(object):\n",
    "    def __init__(self, entries, output):\n",
    "        self.entries = np.array([entries]).reshape(-1, 1) #it's 5 for deep Learning approche\n",
    "        self.output = np.array([output]).reshape(-1, 1)\n",
    "        self.weights = [np.array([DATAc[x][:4]\n",
    "                        for x in ['0','1','2','3','4']])]\n",
    "        self.bias = [np.ndarray([self.entries.shape[0], 1])]\n",
    "        self.activation = self.activation_function\n",
    "        self.target = [5, 5, 5, 5, 5] #to get 5/5 rate five times on one shot\n",
    "        \n",
    "    \n",
    "    def aggregation_function(self, entries, weights, bias):\n",
    "        aggregation = np.dot(self.entries, self.weights) + self.bias\n",
    "        return aggregation        \n",
    "        \n",
    "    def activation_function(self, z):\n",
    "        return 1.0/(1.0 + np.exp(-z))\n",
    "    \n",
    "    #backpropagation\n",
    "    def activation_function_prime(self, z):\n",
    "        return activation_function(z)*(1-activation_function(z))\n",
    "    \n",
    "    def feed_forward(self, a):\n",
    "        '''\n",
    "        [entries] ---> {function}([5 entries]) <----> /*\\25 weights/*\\ ---> nextlayer ... \n",
    "        \n",
    "        --> output {Cost function} ::: => backpropagation -?\n",
    "        '''\n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            a = activation_function(np.dot(w, a)+b)\n",
    "        return a\n",
    "        \n",
    "        \n",
    "    def Stochastic_Gradient_Descent(self, training_data, epochs, mini_batch_size, eta, test_data=None):\n",
    "        if test_data: n_test = len(test_data)\n",
    "        \n",
    "        n = len(training_data)\n",
    "        for j in  xrange(epochs):\n",
    "            random.shuffle(training_data)\n",
    "            mini_batchs = [\n",
    "                training_data[k:k+mini_batch_size]\n",
    "                for k in xrange(0,n,mini_batch_size)\n",
    "            ]\n",
    "            for mini_batch in mini_batchs:\n",
    "                self.update(mini_batch, eta)\n",
    "                \n",
    "            if test_data:\n",
    "                print('epoch {0}: {1} / {2}').format(j, self.evaluate(test_data), n_test)\n",
    "            else:\n",
    "                print('epoch {0} complete').format(j)\n",
    "                \n",
    "    def update_mini_batchs(self, mini_batchs, eta):\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        for x, y in mini_batchs:\n",
    "            delta_nabla_b, delta_nabla_w = self.backpropagation(x, y)\n",
    "            nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "\n",
    "        self.weights = [w - eta / len(mini_batchs) * nw for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b - eta / len(mini_batchs) * nb for b, nb in zip(self.biases, nabla_b)]\n",
    "        \n",
    "        \n",
    "\n",
    "    def backpropagation(self, x):\n",
    "        #feedforward pass\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        \n",
    "        activation = x\n",
    "        activations = [x]\n",
    "        zs = []\n",
    "        \n",
    "        for b, w in zip(self.biases, self.weights):\n",
    "            z = np.dot(w, activation) + b\n",
    "            zs.append(z)\n",
    "            activation = activation_function(z)\n",
    "            activations.append(activation)\n",
    "            \n",
    "        delta = self.cost_derivative_function(activation[-1], y) * \\\n",
    "        sigmoid_prime(zs)\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "        \n",
    "        for l in xrange(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = activation_function_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        return (nabla_b, nabla_w)\n",
    "    \n",
    "    \n",
    "    def evaluate(self, test_data):\n",
    "        \"\"\"Return the number of test inputs for which the neural\n",
    "        network outputs the correct result. Note that the neural\n",
    "        network's output is assumed to be the index of whichever\n",
    "        neuron in the final layer has the highest activation.\"\"\"\n",
    "        test_results = [(np.argmax(self.feedforward(x)), y)\n",
    "                        for (x, y) in test_data]\n",
    "        return sum(int(x == y) for (x, y) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        \"\"\"Return the vector of partial derivatives \\partial C_x /\n",
    "        \\partial a for the output activations.\"\"\"\n",
    "        return (output_activations-y)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Neural_Network(np.array([DATAc['1']]), np.array([DATAc['Target']]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
       "        13., 14.]])"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([range(15)], dtype=float)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_str_example = data_wrapper(Data2, 2, 1, mode='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 0, 15, 15, 24]\n"
     ]
    }
   ],
   "source": [
    "print(encode_str_example) #encode of relaxed by alphabetic number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "butterfly_effect_code = sum(i for i in encode_str_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Now we may use our wrapper function every time we insert a entries in the Neural Network class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "print(butterfly_effect_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data = [data_wrapper(Data2, i ,2, mode='default') for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "indice = random.choice([1,2,3,4,0])\n",
    "x = sum(i for i in t_data[indice])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.858045336306206e-05"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/53820 #probablity to obtain the same code for 2 different words on the 15 available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
